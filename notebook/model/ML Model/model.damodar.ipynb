{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the data\n",
    "import os\n",
    "os.getcwd()\n",
    "X_train = pd.read_csv('d:\\\\PROJECTS\\\\HACKATHONS\\\\GSTN\\\\datasets\\\\Train_60\\\\Train_60\\\\X_Train_Data_Input.csv')\n",
    "y_train = pd.read_csv('d:\\\\PROJECTS\\\\HACKATHONS\\\\GSTN\\\\datasets\\\\Train_60\\\\Train_60\\\\Y_Train_Data_Target.csv')\n",
    "X_test = pd.read_csv('d:\\\\PROJECTS\\\\HACKATHONS\\\\GSTN\\\\datasets\\\\Test_20\\\\Test_20\\\\X_Test_Data_Input.csv')\n",
    "y_test = pd.read_csv('d:\\\\PROJECTS\\\\HACKATHONS\\\\GSTN\\\\datasets\\\\Test_20\\\\Test_20\\\\Y_Test_Data_Target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new_train = y_train.drop('ID', axis=1)\n",
    "X_new_train = X_train.drop('ID', axis=1)\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "clf.fit(X_new_train,y_new_train)\n",
    "X_test_new = X_test.drop('ID', axis=1)\n",
    "y_test_new = y_test.drop('ID', axis=1)\n",
    "score = clf.score(X_test_new, y_test_new)\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(clf, 'rfm_without_anything.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9269349513969555\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[236649,    385],\n",
       "       [ 18737,   5941]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with some effort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.drop('ID', axis=1, inplace=True)\n",
    "X_train.drop('ID', axis=1, inplace=True)\n",
    "y_test.drop('ID', axis=1, inplace=True)\n",
    "X_test.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "X_train.fillna(X_train.median(), inplace=True)\n",
    "X_train.dropna(axis=1,thresh=(0.6*len(X_train)),inplace=True)\n",
    "X_test.fillna(X_test.median(), inplace=True)\n",
    "X_test.dropna(axis=1,thresh=(0.6*len(X_test)),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PROJECTS\\HACKATHONS\\GSTN\\gstn\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9259529559210125\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "clf.fit(X_train,y_train)\n",
    "score = clf.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score, log_loss, classification_report\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import joblib\n",
    "\n",
    "# ... (CustomFeatureSelector and CustomFeatureEngineering classes remain unchanged)\n",
    "\n",
    "def create_preprocessing_pipeline(X_train):\n",
    "    # Ensure all column names are strings\n",
    "    X_train.columns = X_train.columns.astype(str)\n",
    "\n",
    "    # Define column types (example column names; adjust as needed)\n",
    "    binary_columns = ['Column10', 'Column11', 'Column12', 'Column13', 'Column19', 'Column20', 'Column21']\n",
    "    categorical_columns = ['Column0', 'Column16', 'Column17', 'Column18']\n",
    "    numeric_columns = ['Column1', 'Column2', 'Column3', 'Column4', 'Column5', 'Column6', 'Column7', 'Column8', 'Column14', 'Column15']\n",
    "\n",
    "    # Check if columns exist in the data\n",
    "    def check_columns(columns, data):\n",
    "        return [col for col in columns if col in data.columns]\n",
    "\n",
    "    # Check columns on DataFrame\n",
    "    numeric_columns = check_columns(numeric_columns, X_train)\n",
    "    binary_columns = check_columns(binary_columns, X_train)\n",
    "    categorical_columns = check_columns(categorical_columns, X_train)\n",
    "\n",
    "    # ... (rest of the function remains unchanged)\n",
    "\n",
    "def create_multi_level_architecture(preprocessing_pipeline):\n",
    "    # ... (function remains unchanged)\n",
    "\n",
    "def extended_evaluate_model(model, X_test, y_test):\n",
    "    # ... (function remains unchanged)\n",
    "\n",
    "class ScalableRobustMLSystem:\n",
    "    def __init__(self, X_train):\n",
    "        # Ensure column names are strings\n",
    "        X_train.columns = X_train.columns.astype(str)\n",
    "        \n",
    "        self.preprocessing_pipeline = create_preprocessing_pipeline(X_train)\n",
    "        self.model = create_multi_level_architecture(self.preprocessing_pipeline)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Ensure column names are strings\n",
    "        X.columns = X.columns.astype(str)\n",
    "        print(\"Fitting the model...\")\n",
    "        self.model.fit(X, y)\n",
    "        print(\"Model fitting completed.\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Ensure column names are strings\n",
    "        X.columns = X.columns.astype(str)\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        # Ensure column names are strings\n",
    "        X.columns = X.columns.astype(str)\n",
    "        return self.model.predict_proba(X)\n",
    "    \n",
    "    def evaluate(self, X, y):\n",
    "        # Ensure column names are strings\n",
    "        X.columns = X.columns.astype(str)\n",
    "        print(\"Evaluating the model...\")\n",
    "        extended_evaluate_model(self.model, X, y)\n",
    "    \n",
    "    def cross_validate(self, X, y, cv=5):\n",
    "        # Ensure column names are strings\n",
    "        X.columns = X.columns.astype(str)\n",
    "        print(f\"Performing {cv}-fold cross-validation...\")\n",
    "        cv_scores = cross_val_score(self.model, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "        print(f\"Cross-validation scores: {cv_scores}\")\n",
    "        print(f\"Mean CV accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "        return cv_scores\n",
    "    \n",
    "    def save_model(self, filename):\n",
    "        print(f\"Saving model to {filename}...\")\n",
    "        joblib.dump(self.model, filename)\n",
    "        print(\"Model saved successfully.\")\n",
    "    \n",
    "    def load_model(self, filename):\n",
    "        print(f\"Loading model from {filename}...\")\n",
    "        self.model = joblib.load(filename)\n",
    "        print(\"Model loaded successfully.\")\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your data\n",
    "    X_train = pd.read_csv('/kaggle/input/gstn-hackathon/X_Train_Data_Input.csv')\n",
    "    y_train = pd.read_csv('/kaggle/input/gstn-hackathon/Y_Train_Data_Target.csv')\n",
    "    X_test = pd.read_csv('/kaggle/input/gstn-hackathon/X_Test_Data_Input.csv')\n",
    "    y_test = pd.read_csv('/kaggle/input/gstn-hackathon/Y_Test_Data_Target.csv')\n",
    "\n",
    "    # Ensure all column names are strings\n",
    "    X_train.columns = X_train.columns.astype(str)\n",
    "    X_test.columns = X_test.columns.astype(str)\n",
    "    y_train.columns = y_train.columns.astype(str)\n",
    "    y_test.columns = y_test.columns.astype(str)\n",
    "\n",
    "    # Drop 'ID' column from X_train and X_test if it exists\n",
    "    if 'ID' in X_train.columns:\n",
    "        X_train.drop(columns=['ID', 'Column9'], inplace=True)\n",
    "    if 'ID' in X_test.columns:\n",
    "        X_test.drop(columns=['ID', 'Column9'], inplace=True)\n",
    "    if 'ID' in y_train.columns:\n",
    "        y_train.drop(columns=['ID'], inplace=True)\n",
    "    if 'ID' in y_test.columns:\n",
    "        y_test.drop(columns=['ID'], inplace=True)\n",
    "    \n",
    "    # Convert target to 1D array\n",
    "    y_train = y_train.values.ravel()\n",
    "    y_test = y_test.values.ravel()\n",
    "\n",
    "    # Create and train the system\n",
    "    ml_system = ScalableRobustMLSystem(X_train)\n",
    "    ml_system.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the system\n",
    "    ml_system.evaluate(X_test, y_test)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    ml_system.cross_validate(X_train, y_train)\n",
    "\n",
    "    # Save the model\n",
    "    ml_system.save_model('scalable_robust_ml_model.joblib')\n",
    "\n",
    "    # To load the model later\n",
    "    # ml_system.load_model('scalable_robust_ml_model.joblib')\n",
    "\n",
    "    # To process new test data\n",
    "    # new_predictions = ml_system.predict(new_test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gstn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
